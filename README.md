# ðŸ‘‹ Hi, I'm Hongping Zhang

Independent AI Researcher | Energy Efficiency & Sustainable Computing

---

## ðŸ”¬ Research Highlights

### ðŸ† Energy Efficiency of Quantized LLM Inference

**[Paper (Draft)](https://github.com/hongping-zh/ecocompute-dynamic-eval) | [Dashboard](https://hongping-zh.github.io/ecocompute-dynamic-eval/) | [Batch Size Analysis](https://hongping-zh.github.io/ecocompute-dynamic-eval/?view=BATCH_SIZE) | [Metadata](https://github.com/hongping-zh/ecocompute-dynamic-eval/tree/main/metadata)**

> **Breakthrough Finding**: Discovered that bitsandbytes INT8 increases energy by 17-147% due to mixed-precision decomposition. Causal diagnosis via ablation recovered **+79-98% throughput** and **âˆ’35-41% energy** across consumer (RTX 4090D) and datacenter (A800) GPUs.

> **NEW â€” Batch Size Optimization**: A800 sweep (BS 1â†’64) shows **95.7% energy reduction** and **55.5Ã— throughput scaling**. BS=1 wastes 55% GPU capacity. Interactive results: [**View Dashboard â†’**](https://hongping-zh.github.io/ecocompute-dynamic-eval/?view=BATCH_SIZE)

> **Research Scope**: This work focuses on energy efficiency diagnosis. Accuracy assessment (perplexity, downstream tasks) is not yet complete. Pure INT8 (`threshold=0.0`) shows major performance gains, but accuracy impact requires validation. Next steps: PPL and MMLU evaluationâ€”contributions welcome!

**Key Contributions**:
- ðŸŽ¯ **Root cause identified**: Mixed-precision decomposition, not INT8 itself
- ðŸ“Š **93+ measurements** (CV < 1-2%) across **3 GPU architectures**: RTX 5090 (Blackwell), RTX 4090D (Ada Lovelace), A800 (Ampere)
- ðŸ“ˆ **Batch size scaling law**: 95.7% energy reduction (BS=1â†’64), validated on A800 with 70 measurements
- âœ… **Cross-platform validation**: Consistent results across consumer & datacenter GPUs, multiple models
- ðŸ”“ **Full reproducibility**: Complete metadata with software versions, configs, and protocols
- ðŸŒ **Open data**: All raw data, scripts, interactive dashboard, and provenance publicly available

**Impact**: Prevents industry from drawing wrong conclusions about INT8 quantization. Provides actionable guidance for practitioners deploying quantized LLMs in production.

**Status**: Preparing for arXiv submission. [bitsandbytes Issue filed](https://github.com/bitsandbytes-foundation/bitsandbytes/issues/1851).

---

## ðŸ“Š Research Standards

All my benchmarks follow rigorous reproducibility standards:

- âœ… **Complete metadata** with hardware specs, software versions, and model commits
- âœ… **Statistical rigor** (n=10, CV < 2%, significance tests)
- âœ… **Open data** with full provenance and reproducible scripts
- âœ… **Causal analysis** via controlled experiments and ablations
- âœ… **Cross-architecture validation** (Blackwell + Ada Lovelace + Ampere)

ðŸ“ **[View Metadata Standards â†’](https://github.com/hongping-zh/ecocompute-dynamic-eval/tree/main/metadata)**

---

## ðŸ› ï¸ Tech Stack

**Languages**: Python, TypeScript, Bash  
**ML/AI**: PyTorch, Transformers, bitsandbytes, CUDA  
**Data**: Pandas, NumPy, SciPy, Matplotlib  
**Tools**: Git, Docker, Jupyter, VS Code  
**Cloud**: AutoDL, AWS (occasional)

---

## ðŸ“ˆ Current Projects

### ðŸŒ± EcoCompute Dynamic Eval
Interactive dashboard for comparing AI models by accuracy, cost, and carbon footprint. Features a **[Batch Size Analysis page](https://hongping-zh.github.io/ecocompute-dynamic-eval/?view=BATCH_SIZE)** with interactive charts and cost calculator.

**Tech**: TypeScript, React, Recharts, TailwindCSS, GitHub Pages  
**Data**: 93+ measurements, 8 models, 3 GPU architectures (RTX 5090, RTX 4090D, A800)

### ðŸ”‹ Quantization Energy Research
Systematic study of quantization energy efficiency on modern GPUs. Discovered two paradoxes (NF4 and bitsandbytes INT8) and provided causal diagnosis via ablation. Latest: **batch size sweep reveals 95.7% energy reduction** potential.

**Tech**: Python, PyTorch, NVML, bitsandbytes  
**Impact**: Prevents ~30-96% energy waste in production LLM deployments

---

## ðŸ“« Contact

- **Email**: zhanghongping1982@gmail.com
- **GitHub**: [@hongping-zh](https://github.com/hongping-zh)
- **Dashboard**: [ecocompute-dynamic-eval](https://hongping-zh.github.io/ecocompute-dynamic-eval/)

---

## ðŸ’¡ Philosophy

I believe in **open science** and **reproducible research**. Every benchmark I publish includes:
- Complete metadata (hardware, software, models)
- Raw data and analysis scripts
- Reproduction commands
- Known issues and resolutions

**Goal**: Make AI research more transparent, reproducible, and energy-efficient.

---

## ðŸ“Š GitHub Stats

![Hongping's GitHub stats](https://github-readme-stats.vercel.app/api?username=hongping-zh&show_icons=true&theme=default)

---

*"Measure, don't assume. Reproduce, don't trust. Share, don't hoard."*
